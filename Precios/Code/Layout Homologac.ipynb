{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitar duplicados sin tomar en cuenta la descripción del producto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_load = r'C:\\Users\\jshernandezm\\OneDrive - genommalabinternacional\\02Paises\\MEX\\DB Request\\Homologaciones'\n",
    "filename_load = 'Homologa Farmacon S20.xlsx'\n",
    "\n",
    "path_export = r'C:\\Users\\jshernandezm\\OneDrive - genommalabinternacional\\MEX\\Precios\\Data\\2022\\Homologar'\n",
    "filename_export = 'Hom_Farcon_S20.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                     'Server=SFEDWH01;'\n",
    "                     'Trusted_Connection=yes;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qweek_year = '''SELECT TmpFecha\n",
    "                  ,TmpSemanaAnioGenomma Semana\n",
    "                  ,TmpAnioSemanaGenomma Anio\n",
    "            FROM Gnm_DWH.dbo.Dim_Tiempo'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qsemid = '''SELECT SemID\n",
    "                   ,SemAnio\n",
    "                   ,SemNumero\n",
    "                   ,SemInicio\n",
    "            FROM Gnm_MasterOp.dbo.CatSemanas'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qproducts = '''SELECT DISTINCT PR.ProPstCodBarras AS EAN\n",
    "               ,PR.ProPstNombre AS Descripción\n",
    "               ,PR.ProPstID\n",
    "FROM Gnm_MasterOp.dbo.GnmPresentacionesProd AS PR\n",
    "RIGHT JOIN Gnm_MasterOp.dbo.GnmTiposComProd AS PA\n",
    "ON PA.TipoComProd = PR.TipoComProd\n",
    "WHERE PA.TipoComNombre LIKE '%canal%'\n",
    "      AND PR.ProPstCodBarras IN ({0})\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    path_load + '\\\\' + filename_load, \n",
    "    sheet_name='Datos', \n",
    "    header=9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtra solo las filas que necesitan homologación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['SoutRchFecha', 'SoutRchCliente', 'Cadena', 'SoutRchCodProd']][df['SoutRchRazon']=='[ProductoCliente(Unmatched)]']\n",
    "df['SoutRchFecha'] = df['SoutRchFecha'].dt.date\n",
    "df['SoutRchFecha'] = pd.to_datetime(df['SoutRchFecha'])\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From DWH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traemos años, semana y ID de semana:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dweek_year = pd.read_sql(qweek_year, conn)\n",
    "dsemid = pd.read_sql(qsemid, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos a qué semana le pertence las fechas de *SoutRchFecha*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = df.merge(dweek_year, left_on='SoutRchFecha', right_on='TmpFecha', how='left')\n",
    "layout = layout[['SoutRchCliente', 'Anio', 'Semana', 'Cadena', 'SoutRchCodProd']]\n",
    "layout.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ocasiones pasan muchas semanas sin homologar un sku, por lo que no es necesario homologarlo tantas veces, lo que se necesita es homolgar una sola vez pero con la semana más antigua. <br>\n",
    "La siguiente función tomará la columna *SoutRchCodProd* y revisará cuántos skus repetidos hay, después para cada sku tomará la semana más antigua y la reemplazará en las demás semanas para que al final quitemos valores duplicados. Así obtendremos valores sin repetir en *Semana* y *SoutRchCodProd*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(data, column_rep, column_fix, method='min'):\n",
    "    '''\n",
    "    data: Son los datos a comparar\n",
    "    column_rep: Columna donde hay valores repetidos (para este caso, SoutRchCodProd o EAN)\n",
    "    column_fix: Columna con los valores a imputar (para este caso, Semana o ProPstID)\n",
    "    method: Solo toma el valor mínimo ('min') o máximo ('max') de column_fix\n",
    "    '''\n",
    "    skus_values = data[column_rep].value_counts()[data[column_rep].value_counts() > 1].index.tolist()\n",
    "    for val in skus_values:\n",
    "        if method == 'min':\n",
    "            value_fill = data.loc[data[column_rep] == val, column_fix].min()\n",
    "        else:\n",
    "            value_fill = data.loc[data[column_rep] == val, column_fix].max()\n",
    "        data.loc[data[column_rep] == val, column_fix] = value_fill\n",
    "    return data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos quedamos con el código de producto del cliente (SoutRchCodProd) único por la semana más antigua:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = remove_duplicates(layout, column_rep='SoutRchCodProd', column_fix='Semana')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por seguridad homologamos 2 semanas antes de que hayan aparecidos los productos. Para realizar 2 semanas hacia atrás restaremos dos semanas a la columna *SemID*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = layout.merge(\n",
    "    dsemid, \n",
    "    left_on=['Anio', 'Semana'], \n",
    "    right_on=['SemAnio', 'SemNumero'], \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = layout[['SemID', 'SoutRchCliente', 'Cadena', 'SoutRchCodProd']]\n",
    "layout['SemID'] = layout['SemID'] - 2\n",
    "layout = layout.merge(dsemid, on='SemID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto ya tenemos la información de las semanas, pero nos falta la de los productos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_skus = \", \".join(map(str, layout['SoutRchCodProd'].unique()))\n",
    "dproducts = pd.read_sql(qproducts.format(total_skus), conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trateremos de quedarnos con los EAN y ProPstID únicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dproducts = remove_duplicates(dproducts, column_rep='EAN', column_fix='ProPstID', method='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque para el caso de los productos la función *remove_duplicates* no asegura que sean únicos, pues si hay un EAN y ProPstID con diferentes descripciones nos indica que es un registro duplicado, por lo consiguiente será asegurarnos de que sean únicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un catálogo de EAN y Descripción\n",
    "names_sku = dproducts[['EAN', 'Descripción']].copy()\n",
    "# Ahora sí nos quedamos con los productos únicos\n",
    "dproducts = dproducts[['EAN', 'ProPstID']].drop_duplicates()\n",
    "# Iteramos todos los renglones y asignamos nombres\n",
    "dproducts['Descripción'] = pd.Series()\n",
    "for row in range(dproducts.shape[0]):\n",
    "    ean = dproducts.loc[row, 'EAN']\n",
    "    names = names_sku['Descripción'][names_sku['EAN']==ean].tolist()\n",
    "    dproducts.loc[row, 'Descripción'] = random.choice(names)\n",
    "# Eliminamos el catálogo\n",
    "del names_sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos el layout final\n",
    "layout = layout.merge(dproducts, left_on='SoutRchCodProd', right_on='EAN', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambiamos el nombre de las columnas para exportar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.rename({\n",
    "    'SemInicio':'SoutRchFechaCarga',\n",
    "    'SemAnio':'SoutRchAnio',\n",
    "    'SemNumero':'Sem'\n",
    "    }, \n",
    "    axis=1, \n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout['SoutRchFecha'] = layout['SoutRchFechaCarga']\n",
    "layout['Mes'] = 0\n",
    "\n",
    "layout = layout[['SoutRchFechaCarga', 'SoutRchCliente', 'SoutRchFecha', 'SoutRchAnio', 'Mes', 'Sem', 'Cadena', 'SoutRchCodProd', 'Descripción', 'ProPstID']]\n",
    "\n",
    "layout['Cadena'] = layout['Cadena'].map(int).map(str)\n",
    "layout['SoutRchCodProd'] = layout['SoutRchCodProd'].map(int).map(str)\n",
    "\n",
    "layout['Descripción'].fillna(value='ALTA', inplace=True)\n",
    "layout['ProPstID'].fillna(value='ALTA', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout.to_excel(path_export + '\\\\' + filename_export, index=False, sheet_name='Homologar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe4feffa201cdf201c8a2af344ba7b0bb32861ea0c787625218332493d6906c2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
