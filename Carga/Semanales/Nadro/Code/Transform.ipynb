{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2022\n",
    "month = 'Febrero'\n",
    "week = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from datetime import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '{0}_{1}_Nadro.xlsx'.format(year, str(week).zfill(2))\n",
    "\n",
    "path_export = r'\\\\NASPRO.infovisiontv.com\\Respaldo_Operacion_Cargas\\Nadro\\{0}\\Layout Diario'\n",
    "path_export = path_export.format(year)\n",
    "\n",
    "filename_export = '{0}_{1}_NadroV5GLI_{3}-{2}-{0}_S{1}_Real test.txt'\n",
    "\n",
    "path_backup = r'\\\\NASPRO.infovisiontv.com\\Respaldo_Operacion_Cargas\\Nadro\\{0}'\n",
    "path_backup = path_backup.format(year)\n",
    "\n",
    "path_load = r'C:\\Users\\jshernandezm\\OneDrive - genommalabinternacional\\MEX\\Carga\\Semanales\\Nadro\\Data\\{0}\\2. {2}\\S {1}'\n",
    "path_load = path_load.format(year, str(week).zfill(2), month)\n",
    "\n",
    "path_file_catalog = r'\\\\NASPRO.infovisiontv.com\\Respaldo_Operacion_Cargas\\Nadro\\Catalogos.xlsx'\n",
    "sheet_sucs = 'Sucursales'\n",
    "sheet_inv = 'Inventarios'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect('Driver={SQL Server};'\n",
    "                      'Server=SFEDWH01;'\n",
    "                      'Trusted_Connection=yes;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdates = '''SELECT SemAnio,\n",
    "                  SemNumero,\n",
    "                  SemInicio,\n",
    "                  SemFin\n",
    "                  FROM Gnm_MasterOp.dbo.CatSemanas\n",
    "                  WHERE SemAnio>={0} AND SemNumero BETWEEN {1} AND {2}'''\n",
    "\n",
    "qdates = qdates.format(year, week - 1, week)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jshernandezm\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ddates = pd.read_sql(qdates, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = ddates['SemFin'][ddates['SemNumero'] == ddates['SemNumero'].max()]\n",
    "day = date.squeeze().day\n",
    "month = date.squeeze().month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos 2 catálogos:\n",
    "- *sucs* es un catálogo referente a las sucursales.\n",
    "- *inv* es un catálogo sobre el inventario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sucs = pd.read_excel(path_file_catalog, sheet_name=sheet_sucs, usecols='A, D')\n",
    "inv = pd.read_excel(path_file_catalog, sheet_name=sheet_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos solo las columnas que nos interesan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['EAN', 'SAP', 'MATERIAL', 'CS', 'PFCIA', 'PPUB', 'CTRO', 'EXIS', 'TRANS', 'TOT PZAS']\n",
    "data = pd.read_excel(path_load + '\\\\' + filename)\n",
    "data = data[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En ocasiones, el reporte tiene filas en blanco al final, por lo que se las quitamos en seguida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_remove = data[-10:].T.isnull().sum()[data[-10:].T.isnull().sum()==9].index\n",
    "data = data.iloc[[i for i in data.index if i not in index_to_remove], :]\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de columna \"DEMANDA\"\n",
    "data['DEMANDA'] = data['TOT PZAS']*4\n",
    "# Limpieza de columna \"EAN\"\n",
    "data['EAN'] = data['EAN'].map(int)\n",
    "data.loc[data['EAN'].isin([7501004227620, 7501004227644, 7501004226890]), 'DEMANDA'] = data.loc[data['EAN'].isin([7501004227620, 7501004227644, 7501004226890]), 'DEMANDA']*3\n",
    "data.loc[data['EAN']==7501004229983, 'EAN'] = 650240010736\n",
    "# Limpieza de columna \"SAP\"\n",
    "data['SAP'] = data['SAP'].map(int)\n",
    "data = data[~data['SAP'].isin([44362, 44363])]\n",
    "# Imputamos 0 a la columna \"TRANS\"\n",
    "data['TRANS'].fillna(0, inplace=True)\n",
    "# Cambiamos el tipo de dato a entero a la columna \"CTRO\"\n",
    "data['CTRO'] = data['CTRO'].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos algunas columnas de los datos semanales\n",
    "data.rename({\n",
    "    'SAP':'CODIGO', \n",
    "    'MATERIAL':'DESCRIPCION',\n",
    "    'CTRO':'Sucursal ID',\n",
    "    'EXIS':'EXISTENCIA', \n",
    "    'TRANS':'TRANSITO'\n",
    "}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombramos la columna Concat-Suc de sucs\n",
    "sucs.rename({\n",
    "    'Concat-Suc':'SUCURSAL'\n",
    "}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Cruce con sucs\n",
    "rows_before = data.shape[0]\n",
    "data = data.merge(sucs, on='Sucursal ID', how='left')\n",
    "rows_after = data.shape[0]\n",
    "print(rows_before == rows_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llave para cruzar con inv\n",
    "data['Llave'] = data['CODIGO'].map(str) + '-' + data['SUCURSAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Cruce con inv\n",
    "rows_before = data.shape[0]\n",
    "data = data.merge(inv, on='Llave', how='left')\n",
    "rows_after = data.shape[0]\n",
    "print(rows_before == rows_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí ya con las columnas de los catálogos se limpian los datos antes de ser exportados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['SUCURSAL']=='50CEDI', 'TRANSITO'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación de datos con 0\n",
    "for c in ['DPZTL_NOV_18', 'DPZTL_DIC_18', 'DPZTL_ENE_19']:\n",
    "    data[c].fillna(0, inplace=True)\n",
    "# Cambia el tipo de dato a entero\n",
    "for c in ['DPZTL_DIC_18', 'DPZTL_ENE_19', 'DPZTL_NOV_18', 'EXISTENCIA', 'TRANSITO']:\n",
    "    final[c] = final[c].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos quedamos con registros únicos\n",
    "final = data.pivot_table(index=['EAN', \n",
    "                                'CODIGO', \n",
    "                                'DESCRIPCION',\n",
    "                                'CS',\n",
    "                                'PFCIA', \n",
    "                                'PPUB',\n",
    "                                'SUCURSAL'], \n",
    "                        values= ['EXISTENCIA',\n",
    "                                 'TRANSITO', \n",
    "                                 'DEMANDA',\n",
    "                                 'DPZTL_NOV_18',\n",
    "                                 'DPZTL_DIC_18',\n",
    "                                 'DPZTL_ENE_19'], \n",
    "                        aggfunc='sum').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una columna nueva \"DOIS\"\n",
    "final['DOIS'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una lista *cols* que tiene el orden de columnas de cómo se exportará el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'EAN',\n",
    "    'CODIGO',\n",
    "    'DESCRIPCION',\n",
    "    'CS',\n",
    "    'PFCIA',\n",
    "    'PPUB',\n",
    "    'SUCURSAL',\n",
    "    'EXISTENCIA',\n",
    "    'TRANSITO',\n",
    "    'DEMANDA',\n",
    "    'DPZTL_NOV_18',\n",
    "    'DPZTL_DIC_18',\n",
    "    'DPZTL_ENE_19',\n",
    "    'DOIS'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_export = filename_export.format(year, week, month, day)\n",
    "# csv.QUOTE_NONNUMERIC le agrega '\"' a las columnas object\n",
    "final[cols].to_csv(path_backup + '\\\\' + filename_export, index=False, quoting=csv.QUOTE_NONNUMERIC, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8517f3e7e53f8964ccb37c76b9649d71f1b5b080f0cd17a0a1c63227e7ee36f6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
